{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-24 05:10:19.348027: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-24 05:10:19.534765: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-24 05:10:19.534799: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-24 05:10:20.468547: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-24 05:10:20.468717: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-24 05:10:20.468734: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.11.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf;\n",
    "\n",
    "train = pd.read_pickle(config.TRAIN)\n",
    "test = pd.read_pickle(config.TEST)\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing with tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "678D     find long function four onli note valu integ s...\n",
       "915F     follow maximum connect simpl differ function p...\n",
       "708B     input a11 four exist determin prove integ nega...\n",
       "256B     adjac initi four space left squar integ coordi...\n",
       "1535E    bufferedwrit input solv initi left cours integ...\n",
       "                               ...                        \n",
       "990C     follow name bracket concaten \"()()()\". oper ar...\n",
       "1154C    input correspond stew long plan four sunday in...\n",
       "339C     pan correspond order zero left integ littl spe...\n",
       "909D     input order oper four left integ etc color lef...\n",
       "582E     follow five correspond variabl oper four space...\n",
       "Name: problem_statement, Length: 6272, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"problem_statement\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6272, 174)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "MAX_SEQUENCE_LENGTH = 174 \n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train[\"problem_statement\"])\n",
    "X_train = tokenizer.texts_to_sequences(train[\"problem_statement\"])\n",
    "X_train = pad_sequences(X_train, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6272,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def y_pick_tag(y, _tag):\n",
    "    \"\"\" for training only on _tag\"\"\"\n",
    "    y[[_tag]]=1\n",
    "    for idx in y.index:\n",
    "        if _tag not in y.loc[idx,\"tags\"]:\n",
    "            y.loc[idx,_tag] = 0\n",
    "    return y[_tag]\n",
    "\n",
    "y_train = train[[\"tags\"]]\n",
    "y_train = y_pick_tag(y_train, \"implementation\")\n",
    "y_train = np.array(y_train)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1568, 174), (1568,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(test[\"problem_statement\"])\n",
    "X_test = tokenizer.texts_to_sequences(test[\"problem_statement\"])\n",
    "X_test = pad_sequences(X_test, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "\n",
    "y_test = test[[\"tags\"]]\n",
    "y_test = y_pick_tag(y_test, \"implementation\")\n",
    "y_test = np.array(y_test)\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline.\n",
    "baseline. logistic regression on tag: implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7136479591836735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# logistic regression with sklearn for baseline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_clf = LogisticRegression(solver=\"sag\",random_state=config.SEED)\n",
    "log_clf.fit(X_train, y_train);\n",
    "y_pred = log_clf.predict(X_test);\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "# 0.7136479591836735 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN\n",
    "https://github.com/NLP-kr/tensorflow-ml-nlp-tf2/blob/master/4.TEXT_CLASSIFICATION/4.1.6%20RNN%20Classification.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6272, 174), (6272,), (1568, 174), (1568,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "tf.random.set_seed(config.SEED)\n",
    "\n",
    "model_name = 'rnn_classifier_en'\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 5\n",
    "VALID_SPLIT = 0.1\n",
    "MAX_LEN = X_train.shape[1]\n",
    "VOCAB_SIZE = 200\n",
    "WORD_EMBEDDING_DIM = 100\n",
    "HIDDEN_STATE_DIM = 150\n",
    "DENSE_FEATURE_DIM = 150\n",
    "DATA_OUT_PATH = \"./data/\"\n",
    "\n",
    "kargs = {'model_name': model_name,\n",
    "        'vocab_size': VOCAB_SIZE,\n",
    "        'embedding_dimension': 100,\n",
    "        'dropout_rate': 0.2,\n",
    "        'lstm_dimension': 150,\n",
    "        'dense_dimension': 150,\n",
    "        'output_dimension':1}\n",
    "\n",
    "class RNNClassifier(tf.keras.Model):\n",
    "    def __init__(self, **kargs):\n",
    "        super(RNNClassifier, self).__init__(name=kargs['model_name'])\n",
    "        self.embedding = layers.Embedding(input_dim=kargs['vocab_size'],\n",
    "                                     output_dim=kargs['embedding_dimension'])\n",
    "        self.lstm_1_layer = tf.keras.layers.LSTM(kargs['lstm_dimension'], return_sequences=True)\n",
    "        self.lstm_2_layer = tf.keras.layers.LSTM(kargs['lstm_dimension'])\n",
    "        self.dropout = layers.Dropout(kargs['dropout_rate'])\n",
    "        self.fc1 = layers.Dense(units=kargs['dense_dimension'],\n",
    "                           activation=tf.keras.activations.tanh)\n",
    "        self.fc2 = layers.Dense(units=kargs['output_dimension'],\n",
    "                           activation=tf.keras.activations.sigmoid)\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.lstm_1_layer(x)\n",
    "        x = self.lstm_2_layer(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-24 05:10:25.325433: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-11-24 05:10:25.325504: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-11-24 05:10:25.325542: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (HJ-ThinkPadX1C8): /proc/driver/nvidia/version does not exist\n",
      "2022-11-24 05:10:25.325891: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = RNNClassifier(**kargs)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=1)\n",
    "checkpoint_path = DATA_OUT_PATH + model_name + '/weights.h5'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'rnn_classifier_en/embedding/embedding_lookup' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/traitlets/config/application.py\", line 982, in launch_instance\n      app.start()\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_4308/192797700.py\", line 1, in <module>\n      history = model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS,\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/tmp/ipykernel_4308/1288449911.py\", line 38, in call\n      x = self.embedding(x)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/keras/layers/core/embedding.py\", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'rnn_classifier_en/embedding/embedding_lookup'\nindices[124,2] = 466 is not in [0, 200)\n\t [[{{node rnn_classifier_en/embedding/embedding_lookup}}]] [Op:__inference_train_function_5569]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, batch_size\u001b[39m=\u001b[39;49mBATCH_SIZE, epochs\u001b[39m=\u001b[39;49mNUM_EPOCHS,\n\u001b[1;32m      2\u001b[0m     validation_split\u001b[39m=\u001b[39;49mVALID_SPLIT, callbacks\u001b[39m=\u001b[39;49m[earlystop_callback, cp_callback])\n",
      "File \u001b[0;32m~/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'rnn_classifier_en/embedding/embedding_lookup' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/traitlets/config/application.py\", line 982, in launch_instance\n      app.start()\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_4308/192797700.py\", line 1, in <module>\n      history = model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS,\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/tmp/ipykernel_4308/1288449911.py\", line 38, in call\n      x = self.embedding(x)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jhojin/CODE/codeforces_tag_predict/.venv/lib/python3.8/site-packages/keras/layers/core/embedding.py\", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'rnn_classifier_en/embedding/embedding_lookup'\nindices[124,2] = 466 is not in [0, 200)\n\t [[{{node rnn_classifier_en/embedding/embedding_lookup}}]] [Op:__inference_train_function_5569]"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS,\n",
    "    validation_split=VALID_SPLIT, callbacks=[earlystop_callback, cp_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "efdbb84c7f1ad0c5977d952beefe4acb7ff5e26beaeb908d058029576baaae6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
